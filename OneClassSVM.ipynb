{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWQMTN9x3eIebFY9Xr4teY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkchheda27/ACM-ICPC-Algorithms/blob/master/OneClassSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "ozZEUaUvQCbS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_port_number(message):\n",
        "    # Use regular expression to extract the port number\n",
        "    match = re.search(r\"port (\\d+)\", message, re.IGNORECASE)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def label_windows(json_data, window_size=7, anomaly_prob=0.1):\n",
        "    windows = []\n",
        "    labels = []\n",
        "    num_objects = len(json_data)\n",
        "    for i in range(num_objects - window_size + 1):\n",
        "        window = json_data[i:i+window_size]\n",
        "        if random.random() < anomaly_prob:\n",
        "            label = 'anomalous'\n",
        "        else:\n",
        "            label = 'normal'\n",
        "        temp=[]\n",
        "        for log in window:\n",
        "            temp.append(log['Message'])\n",
        "        events = [log[\"Message\"].split()[-1] for log in window]\n",
        "\n",
        "        # Extract port numbers\n",
        "        ports = [extract_port_number(log[\"Message\"]) for log in window]\n",
        "        port_dict = {}\n",
        "        for x in ports:\n",
        "            if x not in port_dict and x is not None:\n",
        "                port_dict[x]=0\n",
        "\n",
        "\n",
        "        target_events = {\n",
        "            \"Change\",\n",
        "            \"up\",\n",
        "            \"Learning\",\n",
        "            \"Forward\",\n",
        "            \"Blocking\",\n",
        "            \"down\",\n",
        "        }\n",
        "\n",
        "        for port,event in zip(ports,events):\n",
        "            if event in target_events:\n",
        "                port_dict[port] += 1\n",
        "\n",
        "        tag = 0\n",
        "        for x in port_dict.keys():\n",
        "            if port_dict[x]>=4:\n",
        "                tag=1\n",
        "\n",
        "        labels.append(tag)\n",
        "        windows.append(temp)\n",
        "    return windows, labels\n",
        "\n",
        "def read_json_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "XvOPFNt7T3of"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data =read_json_file(\"/content/parsed_logs.json\")\n",
        "windows, labels = label_windows(json_data)"
      ],
      "metadata": {
        "id": "nXd1lJT2UHro"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(windows))\n",
        "#out of 1081 logs, window size=7, total 1075 windows\n",
        "\n",
        "#each window has labels associated to it\n",
        "print(len(labels))\n",
        "\n",
        "print(windows[220])\n",
        "\n",
        "print(labels[220])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vVdAcb-Vrlo",
        "outputId": "0206c604-ff21-47ee-d46a-307d92c1f04f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1075\n",
            "1075\n",
            "['B: Major network physical port status change, port 3 Port Forward', 'B: Major network physical port status change, port 3 Port Blocking', 'B: Major network physical port status change, port 3 Link down', 'B: Major Network Topology Change Detected', 'B: Major network physical port status change, port 3 Link up', 'B: Major network physical port status change, port 3 Port Learning', 'B: Major network physical port status change, port 3 Port Forward']\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your preprocessed data (X is a list of windows, y are labels)\n",
        "X = windows  # windows (length 1075)\n",
        "y = labels  # labels (shape: (1075,))\n",
        "\n",
        "X_normal = []\n",
        "y_normal = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "    if y[i] == 0:\n",
        "        X_normal.append(X[i])\n",
        "        y_normal.append(y[i])\n",
        "\n",
        "print(len(X_normal))\n",
        "print(y_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEQLRnn1Jltq",
        "outputId": "54a3eb3c-c023-486f-ca27-66c74a27884a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "647\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your preprocessed data (X is a list of windows, y are labels)\n",
        "X = windows  # windows (length 1075)\n",
        "y = labels  # labels (shape: (1075,))\n",
        "\n",
        "# Convert tokenized windows to numpy array\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c_4EBjBZkSK",
        "outputId": "e4cb78a9-969a-44f3-8d88-c15bd01a1e13"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "752\n",
            "752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize and vectorize text data\n",
        "def vectorize_text_data(windows):\n",
        "    vectorizer = CountVectorizer()  # Using a simple CountVectorizer for tokenization\n",
        "    X = vectorizer.fit_transform([' '.join(window) for window in windows]).toarray()\n",
        "    return X, vectorizer\n",
        "\n",
        "# Function to train One-Class SVM\n",
        "def train_one_class_svm(X, nu_value=0.01):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Train One-Class SVM\n",
        "    clf = OneClassSVM(kernel='rbf', nu=nu_value)  # Adjust parameters as needed\n",
        "    clf.fit(X_scaled)\n",
        "\n",
        "    return clf, scaler"
      ],
      "metadata": {
        "id": "UwaBQnCuVtNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the training data\n",
        "X_normal, vectorizer = vectorize_text_data(X_normal)\n",
        "\n",
        "# Train One-Class SVM with adjusted parameters\n",
        "clf, scaler = train_one_class_svm(X_normal, nu_value=0.05)  # Adjust nu_value as needed\n",
        "\n",
        "# Example of predicting on new data\n",
        "def predict_anomalies(new_window):\n",
        "    # Vectorize the new window\n",
        "    new_window_vectorized = vectorizer.transform([' '.join(new_window)]).toarray()\n",
        "\n",
        "    # Scale the vector\n",
        "    new_window_scaled = scaler.transform(new_window_vectorized)\n",
        "\n",
        "    # Predict on the new window\n",
        "    prediction = clf.predict(new_window_scaled)\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "HTAHWZleYhOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for window in X_test:\n",
        "    prediction = predict_anomalies(window)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"Window {i + 1}: {'Normal' if prediction == 1 else 'Anomaly'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A7TaKT0Yi9x",
        "outputId": "72472d80-7c2a-45de-eff9-b4324320aaf8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([-1]), array([-1]), array([-1]), array([-1]), array([1]), array([-1]), array([1]), array([1]), array([1]), array([1]), array([-1])]\n",
            "Window 1: Normal\n",
            "Window 2: Anomaly\n",
            "Window 3: Anomaly\n",
            "Window 4: Normal\n",
            "Window 5: Anomaly\n",
            "Window 6: Normal\n",
            "Window 7: Normal\n",
            "Window 8: Anomaly\n",
            "Window 9: Anomaly\n",
            "Window 10: Normal\n",
            "Window 11: Normal\n",
            "Window 12: Anomaly\n",
            "Window 13: Anomaly\n",
            "Window 14: Normal\n",
            "Window 15: Normal\n",
            "Window 16: Anomaly\n",
            "Window 17: Anomaly\n",
            "Window 18: Normal\n",
            "Window 19: Anomaly\n",
            "Window 20: Normal\n",
            "Window 21: Normal\n",
            "Window 22: Normal\n",
            "Window 23: Anomaly\n",
            "Window 24: Normal\n",
            "Window 25: Normal\n",
            "Window 26: Normal\n",
            "Window 27: Anomaly\n",
            "Window 28: Normal\n",
            "Window 29: Normal\n",
            "Window 30: Anomaly\n",
            "Window 31: Anomaly\n",
            "Window 32: Anomaly\n",
            "Window 33: Normal\n",
            "Window 34: Normal\n",
            "Window 35: Normal\n",
            "Window 36: Normal\n",
            "Window 37: Normal\n",
            "Window 38: Normal\n",
            "Window 39: Anomaly\n",
            "Window 40: Anomaly\n",
            "Window 41: Normal\n",
            "Window 42: Normal\n",
            "Window 43: Normal\n",
            "Window 44: Normal\n",
            "Window 45: Anomaly\n",
            "Window 46: Normal\n",
            "Window 47: Normal\n",
            "Window 48: Anomaly\n",
            "Window 49: Anomaly\n",
            "Window 50: Normal\n",
            "Window 51: Anomaly\n",
            "Window 52: Normal\n",
            "Window 53: Anomaly\n",
            "Window 54: Normal\n",
            "Window 55: Anomaly\n",
            "Window 56: Normal\n",
            "Window 57: Normal\n",
            "Window 58: Anomaly\n",
            "Window 59: Normal\n",
            "Window 60: Anomaly\n",
            "Window 61: Anomaly\n",
            "Window 62: Anomaly\n",
            "Window 63: Normal\n",
            "Window 64: Normal\n",
            "Window 65: Anomaly\n",
            "Window 66: Anomaly\n",
            "Window 67: Normal\n",
            "Window 68: Normal\n",
            "Window 69: Normal\n",
            "Window 70: Normal\n",
            "Window 71: Normal\n",
            "Window 72: Anomaly\n",
            "Window 73: Anomaly\n",
            "Window 74: Normal\n",
            "Window 75: Anomaly\n",
            "Window 76: Normal\n",
            "Window 77: Anomaly\n",
            "Window 78: Anomaly\n",
            "Window 79: Normal\n",
            "Window 80: Anomaly\n",
            "Window 81: Anomaly\n",
            "Window 82: Normal\n",
            "Window 83: Normal\n",
            "Window 84: Anomaly\n",
            "Window 85: Normal\n",
            "Window 86: Normal\n",
            "Window 87: Anomaly\n",
            "Window 88: Normal\n",
            "Window 89: Normal\n",
            "Window 90: Anomaly\n",
            "Window 91: Anomaly\n",
            "Window 92: Anomaly\n",
            "Window 93: Anomaly\n",
            "Window 94: Anomaly\n",
            "Window 95: Anomaly\n",
            "Window 96: Normal\n",
            "Window 97: Anomaly\n",
            "Window 98: Normal\n",
            "Window 99: Anomaly\n",
            "Window 100: Anomaly\n",
            "Window 101: Normal\n",
            "Window 102: Anomaly\n",
            "Window 103: Anomaly\n",
            "Window 104: Anomaly\n",
            "Window 105: Anomaly\n",
            "Window 106: Anomaly\n",
            "Window 107: Normal\n",
            "Window 108: Anomaly\n",
            "Window 109: Anomaly\n",
            "Window 110: Anomaly\n",
            "Window 111: Normal\n",
            "Window 112: Normal\n",
            "Window 113: Anomaly\n",
            "Window 114: Normal\n",
            "Window 115: Anomaly\n",
            "Window 116: Normal\n",
            "Window 117: Normal\n",
            "Window 118: Anomaly\n",
            "Window 119: Anomaly\n",
            "Window 120: Normal\n",
            "Window 121: Anomaly\n",
            "Window 122: Normal\n",
            "Window 123: Anomaly\n",
            "Window 124: Anomaly\n",
            "Window 125: Normal\n",
            "Window 126: Normal\n",
            "Window 127: Normal\n",
            "Window 128: Normal\n",
            "Window 129: Anomaly\n",
            "Window 130: Normal\n",
            "Window 131: Normal\n",
            "Window 132: Anomaly\n",
            "Window 133: Normal\n",
            "Window 134: Normal\n",
            "Window 135: Normal\n",
            "Window 136: Anomaly\n",
            "Window 137: Anomaly\n",
            "Window 138: Normal\n",
            "Window 139: Normal\n",
            "Window 140: Anomaly\n",
            "Window 141: Normal\n",
            "Window 142: Normal\n",
            "Window 143: Anomaly\n",
            "Window 144: Anomaly\n",
            "Window 145: Normal\n",
            "Window 146: Normal\n",
            "Window 147: Normal\n",
            "Window 148: Normal\n",
            "Window 149: Normal\n",
            "Window 150: Anomaly\n",
            "Window 151: Normal\n",
            "Window 152: Anomaly\n",
            "Window 153: Normal\n",
            "Window 154: Normal\n",
            "Window 155: Normal\n",
            "Window 156: Normal\n",
            "Window 157: Normal\n",
            "Window 158: Anomaly\n",
            "Window 159: Normal\n",
            "Window 160: Normal\n",
            "Window 161: Normal\n",
            "Window 162: Anomaly\n",
            "Window 163: Normal\n",
            "Window 164: Normal\n",
            "Window 165: Anomaly\n",
            "Window 166: Anomaly\n",
            "Window 167: Normal\n",
            "Window 168: Anomaly\n",
            "Window 169: Normal\n",
            "Window 170: Anomaly\n",
            "Window 171: Normal\n",
            "Window 172: Anomaly\n",
            "Window 173: Normal\n",
            "Window 174: Normal\n",
            "Window 175: Normal\n",
            "Window 176: Anomaly\n",
            "Window 177: Anomaly\n",
            "Window 178: Normal\n",
            "Window 179: Normal\n",
            "Window 180: Normal\n",
            "Window 181: Normal\n",
            "Window 182: Normal\n",
            "Window 183: Normal\n",
            "Window 184: Normal\n",
            "Window 185: Normal\n",
            "Window 186: Anomaly\n",
            "Window 187: Anomaly\n",
            "Window 188: Normal\n",
            "Window 189: Normal\n",
            "Window 190: Normal\n",
            "Window 191: Normal\n",
            "Window 192: Normal\n",
            "Window 193: Normal\n",
            "Window 194: Normal\n",
            "Window 195: Normal\n",
            "Window 196: Anomaly\n",
            "Window 197: Normal\n",
            "Window 198: Anomaly\n",
            "Window 199: Anomaly\n",
            "Window 200: Normal\n",
            "Window 201: Anomaly\n",
            "Window 202: Normal\n",
            "Window 203: Anomaly\n",
            "Window 204: Anomaly\n",
            "Window 205: Anomaly\n",
            "Window 206: Normal\n",
            "Window 207: Anomaly\n",
            "Window 208: Anomaly\n",
            "Window 209: Anomaly\n",
            "Window 210: Normal\n",
            "Window 211: Normal\n",
            "Window 212: Normal\n",
            "Window 213: Normal\n",
            "Window 214: Anomaly\n",
            "Window 215: Anomaly\n",
            "Window 216: Normal\n",
            "Window 217: Normal\n",
            "Window 218: Normal\n",
            "Window 219: Anomaly\n",
            "Window 220: Anomaly\n",
            "Window 221: Normal\n",
            "Window 222: Anomaly\n",
            "Window 223: Normal\n",
            "Window 224: Normal\n",
            "Window 225: Anomaly\n",
            "Window 226: Normal\n",
            "Window 227: Anomaly\n",
            "Window 228: Normal\n",
            "Window 229: Anomaly\n",
            "Window 230: Normal\n",
            "Window 231: Anomaly\n",
            "Window 232: Normal\n",
            "Window 233: Anomaly\n",
            "Window 234: Normal\n",
            "Window 235: Anomaly\n",
            "Window 236: Normal\n",
            "Window 237: Normal\n",
            "Window 238: Normal\n",
            "Window 239: Normal\n",
            "Window 240: Anomaly\n",
            "Window 241: Anomaly\n",
            "Window 242: Normal\n",
            "Window 243: Normal\n",
            "Window 244: Anomaly\n",
            "Window 245: Anomaly\n",
            "Window 246: Normal\n",
            "Window 247: Normal\n",
            "Window 248: Anomaly\n",
            "Window 249: Normal\n",
            "Window 250: Anomaly\n",
            "Window 251: Normal\n",
            "Window 252: Normal\n",
            "Window 253: Normal\n",
            "Window 254: Anomaly\n",
            "Window 255: Normal\n",
            "Window 256: Anomaly\n",
            "Window 257: Anomaly\n",
            "Window 258: Anomaly\n",
            "Window 259: Anomaly\n",
            "Window 260: Normal\n",
            "Window 261: Anomaly\n",
            "Window 262: Normal\n",
            "Window 263: Normal\n",
            "Window 264: Anomaly\n",
            "Window 265: Normal\n",
            "Window 266: Anomaly\n",
            "Window 267: Normal\n",
            "Window 268: Anomaly\n",
            "Window 269: Normal\n",
            "Window 270: Normal\n",
            "Window 271: Anomaly\n",
            "Window 272: Normal\n",
            "Window 273: Normal\n",
            "Window 274: Normal\n",
            "Window 275: Normal\n",
            "Window 276: Anomaly\n",
            "Window 277: Anomaly\n",
            "Window 278: Anomaly\n",
            "Window 279: Anomaly\n",
            "Window 280: Anomaly\n",
            "Window 281: Anomaly\n",
            "Window 282: Anomaly\n",
            "Window 283: Normal\n",
            "Window 284: Normal\n",
            "Window 285: Anomaly\n",
            "Window 286: Normal\n",
            "Window 287: Normal\n",
            "Window 288: Normal\n",
            "Window 289: Anomaly\n",
            "Window 290: Normal\n",
            "Window 291: Normal\n",
            "Window 292: Anomaly\n",
            "Window 293: Anomaly\n",
            "Window 294: Normal\n",
            "Window 295: Normal\n",
            "Window 296: Normal\n",
            "Window 297: Anomaly\n",
            "Window 298: Normal\n",
            "Window 299: Normal\n",
            "Window 300: Normal\n",
            "Window 301: Normal\n",
            "Window 302: Normal\n",
            "Window 303: Normal\n",
            "Window 304: Anomaly\n",
            "Window 305: Anomaly\n",
            "Window 306: Normal\n",
            "Window 307: Anomaly\n",
            "Window 308: Anomaly\n",
            "Window 309: Anomaly\n",
            "Window 310: Anomaly\n",
            "Window 311: Normal\n",
            "Window 312: Anomaly\n",
            "Window 313: Anomaly\n",
            "Window 314: Anomaly\n",
            "Window 315: Anomaly\n",
            "Window 316: Anomaly\n",
            "Window 317: Normal\n",
            "Window 318: Anomaly\n",
            "Window 319: Normal\n",
            "Window 320: Normal\n",
            "Window 321: Normal\n",
            "Window 322: Normal\n",
            "Window 323: Anomaly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM predicts anomalous as -1 and normal as 1\n",
        "#y_test has normal as 0 and anomalous as 1"
      ],
      "metadata": {
        "id": "rs6ur9MGUhPx"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the list of predictions\n",
        "flat_predictions = [0 if pred == 1 else 1 for pred in predictions]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, flat_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpLmWx1YsVr",
        "outputId": "cab94598-da05-42d4-8092-f822cbd596d6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9287925696594427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)\n",
        "print(flat_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9cJve4Yh9lx",
        "outputId": "03bb82f0-a28a-4a80-eb47-7a71665be98b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1]\n",
            "[0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, flat_predictions)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "N6gxyfpnj1Gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45af2a47-4b4e-425d-fe47-9aa69dd14b56"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[170  14]\n",
            " [  9 130]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, flat_predictions)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "su90pFuvM9El",
        "outputId": "b3aeb2a3-57f6-4fa6-8407-a4a1f21b086e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuw0lEQVR4nO3dd5RV9bn44ffQhjpDF4gUAUWMCtgIoiCxRrGEJIheQ7EbNChCLAlSLNyrIogaTTQoFzUaY0ksiRqxi4oiYosRxRKlCQLSdWb//vDH3IwDMoMD8xWeZ61Zy7P3Pnu/+6wlfNizzzm5LMuyAACABFWp7AEAAGBDxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCrAerzzzjtxyCGHREFBQeRyubjvvvsqdP/vv/9+5HK5uOWWWyp0v99lBxxwQBxwwAGVPQaQGLEKJOvdd9+N0047Ldq2bRs1a9aM/Pz86N69e1x99dWxatWqzXrsAQMGxGuvvRaXXnppTJkyJfbaa6/NerwtaeDAgZHL5SI/P3+9r+M777wTuVwucrlcXHnlleXe/yeffBKjRo2KmTNnVsC0wLauWmUPALA+Dz74YPzsZz+LvLy86N+/f+y6666xdu3aeOaZZ2L48OHxxhtvxO9///vNcuxVq1bFtGnT4te//nWceeaZm+UYrVu3jlWrVkX16tU3y/43plq1arFy5cq4//77o2/fviXW3XbbbVGzZs1YvXr1Ju37k08+idGjR0ebNm2ic+fOZX7eI488sknHA7ZuYhVIzpw5c6Jfv37RunXrmDp1ajRv3rx43eDBg2P27Nnx4IMPbrbjL1y4MCIi6tevv9mOkcvlombNmptt/xuTl5cX3bt3jz/+8Y+lYvX222+PI444Iu6+++4tMsvKlSujdu3aUaNGjS1yPOC7xW0AQHIuv/zyWL58efzhD38oEarrtG/fPoYMGVL8+Msvv4yLL7442rVrF3l5edGmTZu48MILY82aNSWe16ZNm+jdu3c888wzsc8++0TNmjWjbdu28b//+7/F24waNSpat24dERHDhw+PXC4Xbdq0iYivfn2+7r//06hRoyKXy5VY9uijj8Z+++0X9evXj7p160aHDh3iwgsvLF6/oXtWp06dGvvvv3/UqVMn6tevH0cffXS89dZb6z3e7NmzY+DAgVG/fv0oKCiIQYMGxcqVKzf8wn7N8ccfH3/7299iyZIlxcumT58e77zzThx//PGltl+8eHEMGzYsdtttt6hbt27k5+fHj370o3j11VeLt3niiSdi7733joiIQYMGFd9OsO48DzjggNh1113j5Zdfjh49ekTt2rWLX5ev37M6YMCAqFmzZqnzP/TQQ6NBgwbxySeflPlcge8usQok5/7774+2bdvGvvvuW6btTz755Ljoootijz32iPHjx0fPnj1j7Nix0a9fv1Lbzp49O37605/GwQcfHOPGjYsGDRrEwIED44033oiIiD59+sT48eMjIuK4446LKVOmxIQJE8o1/xtvvBG9e/eONWvWxJgxY2LcuHFx1FFHxbPPPvuNz/vHP/4Rhx56aCxYsCBGjRoVQ4cOjeeeey66d+8e77//fqnt+/btG59//nmMHTs2+vbtG7fcckuMHj26zHP26dMncrlc3HPPPcXLbr/99th5551jjz32KLX9e++9F/fdd1/07t07rrrqqhg+fHi89tpr0bNnz+Jw7NixY4wZMyYiIk499dSYMmVKTJkyJXr06FG8n0WLFsWPfvSj6Ny5c0yYMCF69eq13vmuvvrqaNKkSQwYMCAKCwsjIuJ3v/tdPPLII3HNNddEixYtynyuwHdYBpCQpUuXZhGRHX300WXafubMmVlEZCeffHKJ5cOGDcsiIps6dWrxstatW2cRkT311FPFyxYsWJDl5eVl5557bvGyOXPmZBGRXXHFFSX2OWDAgKx169alZhg5cmT2n3+cjh8/PouIbOHChRuce90xbr755uJlnTt3zpo2bZotWrSoeNmrr76aValSJevfv3+p45144okl9vnjH/84a9So0QaP+Z/nUadOnSzLsuynP/1pduCBB2ZZlmWFhYVZs2bNstGjR6/3NVi9enVWWFhY6jzy8vKyMWPGFC+bPn16qXNbp2fPnllEZDfccMN61/Xs2bPEsocffjiLiOySSy7J3nvvvaxu3brZMcccs9FzBLYerqwCSVm2bFlERNSrV69M2z/00EMRETF06NASy88999yIiFL3tu6yyy6x//77Fz9u0qRJdOjQId57771Nnvnr1t3r+pe//CWKiorK9Jy5c+fGzJkzY+DAgdGwYcPi5bvvvnscfPDBxef5n04//fQSj/fff/9YtGhR8WtYFscff3w88cQTMW/evJg6dWrMmzdvvbcARHx1n2uVKl/9tVFYWBiLFi0qvsVhxowZZT5mXl5eDBo0qEzbHnLIIXHaaafFmDFjok+fPlGzZs343e9+V+ZjAd99YhVISn5+fkREfP7552Xa/oMPPogqVapE+/btSyxv1qxZ1K9fPz744IMSy1u1alVqHw0aNIjPPvtsEycu7dhjj43u3bvHySefHNttt13069cv/vSnP31juK6bs0OHDqXWdezYMT799NNYsWJFieVfP5cGDRpERJTrXA4//PCoV69e3HnnnXHbbbfF3nvvXeq1XKeoqCjGjx8fO+64Y+Tl5UXjxo2jSZMmMWvWrFi6dGmZj/m9732vXG+muvLKK6Nhw4Yxc+bMmDhxYjRt2rTMzwW++8QqkJT8/Pxo0aJFvP766+V63tff4LQhVatWXe/yLMs2+Rjr7qdcp1atWvHUU0/FP/7xj/j5z38es2bNimOPPTYOPvjgUtt+G9/mXNbJy8uLPn36xOTJk+Pee+/d4FXViIjLLrsshg4dGj169Ihbb701Hn744Xj00Ufj+9//fpmvIEd89fqUxyuvvBILFiyIiIjXXnutXM8FvvvEKpCc3r17x7vvvhvTpk3b6LatW7eOoqKieOedd0osnz9/fixZsqT4nf0VoUGDBiXeOb/O16/eRkRUqVIlDjzwwLjqqqvizTffjEsvvTSmTp0ajz/++Hr3vW7Ot99+u9S6f/7zn9G4ceOoU6fOtzuBDTj++OPjlVdeic8//3y9b0pb589//nP06tUr/vCHP0S/fv3ikEMOiYMOOqjUa1LWfziUxYoVK2LQoEGxyy67xKmnnhqXX355TJ8+vcL2D6RPrALJ+dWvfhV16tSJk08+OebPn19q/bvvvhtXX311RHz1a+yIKPWO/auuuioiIo444ogKm6tdu3axdOnSmDVrVvGyuXPnxr333ltiu8WLF5d67roPx//6x2mt07x58+jcuXNMnjy5RPy9/vrr8cgjjxSf5+bQq1evuPjii+Paa6+NZs2abXC7qlWrlrpqe9ddd8XHH39cYtm6qF5f2JfXeeedFx9++GFMnjw5rrrqqmjTpk0MGDBgg68jsPXxpQBActq1axe33357HHvssdGxY8cS32D13HPPxV133RUDBw6MiIhOnTrFgAED4ve//30sWbIkevbsGS+++GJMnjw5jjnmmA1+LNKm6NevX5x33nnx4x//OH75y1/GypUr4/rrr4+ddtqpxBuMxowZE0899VQcccQR0bp161iwYEH89re/je233z7222+/De7/iiuuiB/96EfRrVu3OOmkk2LVqlVxzTXXREFBQYwaNarCzuPrqlSpEr/5zW82ul3v3r1jzJgxMWjQoNh3333jtddei9tuuy3atm1bYrt27dpF/fr144Ybboh69epFnTp1omvXrrHDDjuUa66pU6fGb3/72xg5cmTxR2ndfPPNccABB8SIESPi8ssvL9f+gO8mV1aBJB111FExa9as+OlPfxp/+ctfYvDgwXH++efH+++/H+PGjYuJEycWb3vTTTfF6NGjY/r06XH22WfH1KlT44ILLog77rijQmdq1KhR3HvvvVG7du341a9+FZMnT46xY8fGkUceWWr2Vq1axaRJk2Lw4MFx3XXXRY8ePWLq1KlRUFCwwf0fdNBB8fe//z0aNWoUF110UVx55ZXxgx/8IJ599tlyh97mcOGFF8a5554bDz/8cAwZMiRmzJgRDz74YLRs2bLEdtWrV4/JkydH1apV4/TTT4/jjjsunnzyyXId6/PPP48TTzwxunTpEr/+9a+Ll++///4xZMiQGDduXDz//PMVcl5A2nJZee7EBwCALciVVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZW+U3WNXqcmZljwBQoRZMm7jxjQC+Q+rVLNs1U1dWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIlliFr+m+R7v484TT4r1HLo1Vr1wbRx6we4n1q165dr0/5/Q/sHibBvm14+ZLB8T8p6+IuU9dHtePPD7q1KqxpU8FYL1mvDw9zjnrjDjsoB6xV6eO8cTUf2xw28suHhV7deoYt986eQtOCP9HrMLX1KmVF6/96+M4e+yd613f5qALSvycOvLWKCoqinsfm1m8zc2XDYiO7ZpH7zOujZ/88obYb4/2cd2I47fQGQB8s1WrVsWOHTrEeReM+MbtHn/s0Xj9tVejSZOmW2gyKK1aZQ8AqXnk2TfjkWff3OD6+Ys+L/H4yAN2iyenvxPvf7woIiI67LBdHNr9+9H9vy6PGW9+GBERQ//nrrjvmjPigvH3xtyFSzff8ABl0H2/HtF9vx7fuM2C+fPjiv++NK65/sY4+6zTt9BkUFqlxuqnn34akyZNimnTpsW8efMiIqJZs2ax7777xsCBA6NJkyaVOR5sVNOG9eKw/XaNUy6aUrys6+47xGfLVhaHakTE1BfejqKiLPbetXX89fFZlTEqQJkVFRXFRb8+L34+8MRo137Hyh6HbVyl3QYwffr02GmnnWLixIlRUFAQPXr0iB49ekRBQUFMnDgxdt5553jppZc2up81a9bEsmXLSvxkRYVb4Awg4oQju8bnK1fHfVNnFi/brlF+LFxc8uprYWFRLF62MrZrnL+FJwQov8k33xRVq1aNfsf/vLJHgcq7snrWWWfFz372s7jhhhsil8uVWJdlWZx++ulx1llnxbRp075xP2PHjo3Ro0eXWFZ1u72jevN9Knxm+Lr+R/8g7vzbS7Fm7ZeVPQpAhXjrzTfijtumxK133F3q72eoDJV2ZfXVV1+Nc845Z73/I+RyuTjnnHNi5syZG93PBRdcEEuXLi3xU227PTfDxFBS9y7tosMOzeLme58rsXz+omXRpGG9EsuqVq0SDfNrx/xPl23JEQHK7ZUZL8XixYui92E/jK577Bpd99g15n7ySUwYd3kc+aMDN74DqGCVdmW1WbNm8eKLL8bOO++83vUvvvhibLfddhvdT15eXuTl5ZVYlqtStUJmhG8y4Jhu8fKbH8Zr//q4xPIXZs2JBvm1o0vHlvHKWx9FRMQBe+8UVarkYvrrH1TGqABldnjvo2Kfrt1KLDvrjFPi8N5HxZHH9KmkqdiWVVqsDhs2LE499dR4+eWX48ADDywO0/nz58djjz0WN954Y1x55ZWVNR7bsDq1akS7lv/35r4232sUu+/0vfhs2cr4aN5nERFRr07N6HNwlzj/qntLPf/tOfPj4WffiOtGHB+/vPSOqF6taow/v2/c9fAMnwQAJGHlyhXx0Yf/9ybQjz/+d7z9z7eioKAgmjVvEfXrNyixfbXq1aJR48bRps0OW3pUqLxYHTx4cDRu3DjGjx8fv/3tb6Ow8Ks3RVWtWjX23HPPuOWWW6Jv376VNR7bsD12aR2P3DSk+PHlw34SERFT/vp8nDry1oiI+Nmhe0YucvGnv6//TYCDLpwc48/vGw/97qwoKsrivsdmxrmX37X5hwcogzffeCNOP3lA8ePxV/5PRET0PuqYGHXx2MoaC9Yrl2VZVtlDfPHFF/Hpp59GRETjxo2jevXq32p/tbqcWRFjASRjwbSJlT0CQIWqV7Nsb51K4ksBqlevHs2bN6/sMQAASIyvWwUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSVa0sG82aNavMO9x99903eRgAAPhPZYrVzp07Ry6XiyzL1rt+3bpcLheFhYUVOiAAANuuMsXqnDlzNvccAABQSplitXXr1pt7DgAAKGWT3mA1ZcqU6N69e7Ro0SI++OCDiIiYMGFC/OUvf6nQ4QAA2LaVO1avv/76GDp0aBx++OGxZMmS4ntU69evHxMmTKjo+QAA2IaVO1avueaauPHGG+PXv/51VK1atXj5XnvtFa+99lqFDgcAwLat3LE6Z86c6NKlS6nleXl5sWLFigoZCgAAIjYhVnfYYYeYOXNmqeV///vfo2PHjhUxEwAAREQZPw3gPw0dOjQGDx4cq1evjizL4sUXX4w//vGPMXbs2Ljppps2x4wAAGyjyh2rJ598ctSqVSt+85vfxMqVK+P444+PFi1axNVXXx39+vXbHDMCALCNymUb+lqqMli5cmUsX748mjZtWpEzfWu1upxZ2SMAVKgF0yZW9ggAFapezbLdjVruK6vrLFiwIN5+++2I+OrrVps0abKpuwIAgPUq9xusPv/88/j5z38eLVq0iJ49e0bPnj2jRYsWccIJJ8TSpUs3x4wAAGyjyh2rJ598crzwwgvx4IMPxpIlS2LJkiXxwAMPxEsvvRSnnXba5pgRAIBtVLnvWa1Tp048/PDDsd9++5VY/vTTT8dhhx2WxGetumcV2Nq4ZxXY2pT1ntVyX1lt1KhRFBQUlFpeUFAQDRo0KO/uAABgg8odq7/5zW9i6NChMW/evOJl8+bNi+HDh8eIESMqdDgAALZtZfo0gC5dukQulyt+/M4770SrVq2iVatWERHx4YcfRl5eXixcuNB9qwAAVJgyxeoxxxyzmccAAIDSyhSrI0eO3NxzAABAKeW+ZxUAALaUcn+DVWFhYYwfPz7+9Kc/xYcffhhr164tsX7x4sUVNhwAANu2cl9ZHT16dFx11VVx7LHHxtKlS2Po0KHRp0+fqFKlSowaNWozjAgAwLaq3LF62223xY033hjnnntuVKtWLY477ri46aab4qKLLornn39+c8wIAMA2qtyxOm/evNhtt90iIqJu3bqxdOnSiIjo3bt3PPjggxU7HQAA27Ryx+r2228fc+fOjYiIdu3axSOPPBIREdOnT4+8vLyKnQ4AgG1auWP1xz/+cTz22GMREXHWWWfFiBEjYscdd4z+/fvHiSeeWOEDAgCw7cplWZZ9mx08//zz8dxzz8WOO+4YRx55ZEXN9a3U6nJmZY8AUKEWTJtY2SMAVKh6Nct2zfRbf87qD37wgxg6dGh07do1Lrvssm+7OwAAKFZhXwowd+7cGDFiREXtDgAAfIMVAADpEqsAACRLrAIAkKxqZd1w6NCh37h+4cKF33qYivLZ9GsrewSACtVxuC9dAbYuc8YfUabtyhyrr7zyyka36dGjR1l3BwAAG1XmWH388cc35xwAAFCKe1YBAEiWWAUAIFliFQCAZIlVAACSJVYBAEjWJsXq008/HSeccEJ069YtPv7444iImDJlSjzzzDMVOhwAANu2csfq3XffHYceemjUqlUrXnnllVizZk1ERCxdujQuu+yyCh8QAIBtV7lj9ZJLLokbbrghbrzxxqhevXrx8u7du8eMGTMqdDgAALZt5Y7Vt99+e73fVFVQUBBLliypiJkAACAiNiFWmzVrFrNnzy61/Jlnnom2bdtWyFAAABCxCbF6yimnxJAhQ+KFF16IXC4Xn3zySdx2220xbNiwOOOMMzbHjAAAbKOqlfcJ559/fhQVFcWBBx4YK1eujB49ekReXl4MGzYszjrrrM0xIwAA26hclmXZpjxx7dq1MXv27Fi+fHnssssuUbdu3YqebZOt/rKyJwCoWB2HP1jZIwBUqDnjjyjTduW+srpOjRo1YpdddtnUpwMAwEaVO1Z79eoVuVxug+unTp36rQYCAIB1yh2rnTt3LvH4iy++iJkzZ8brr78eAwYMqKi5AACg/LE6fvz49S4fNWpULF++/FsPBAAA65T7o6s25IQTTohJkyZV1O4AAKDiYnXatGlRs2bNitodAACU/zaAPn36lHicZVnMnTs3XnrppRgxYkSFDQYAAOWO1YKCghKPq1SpEh06dIgxY8bEIYccUmGDAQBAuWK1sLAwBg0aFLvttls0aNBgc80EAAARUc57VqtWrRqHHHJILFmyZDONAwAA/6fcb7Dadddd47333tscswAAQAnljtVLLrkkhg0bFg888EDMnTs3li1bVuIHAAAqSpnvWR0zZkyce+65cfjhh0dExFFHHVXia1ezLItcLheFhYUVPyUAANukXJZlWVk2rFq1asydOzfeeuutb9yuZ8+eFTLYt7H6y8qeAKBidRz+YGWPAFCh5ow/okzblfnK6rqmTSFGAQDYNpTrntX//LU/AABsbuX6nNWddtppo8G6ePHibzUQAACsU65YHT16dKlvsAIAgM2lXLHar1+/aNq06eaaBQAASijzPavuVwUAYEsrc6yW8ROuAACgwpT5NoCioqLNOQcAAJRS7q9bBQCALUWsAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMkSqwAAJEusAgCQLLEKAECyxCoAAMmqVtkDwHfRihXL47qJV8fUx/4Rixcvip077hK/Ov/C2HW33St7NIBS9mnbME79YdvYdfuC2K6gZpz6h5fi0dfnF68fcuiOcWSXFtG8fs34ojCL1/69NMY9+HbM/HBJ8TYFtavHqD7fjwO/3zSyLOJvr86LMfe+ESvXFlbCGbEtcWUVNsGoi34T06Y9F5f+9+Xx53vvj277do/TTh4U8+fP3/iTAbawWjWqxlsfL4uL7n59vevnLFwRI+95PQ674qn42TXPxceLV8bk0/eJhnVqFG8z4YTOsVOzutH/+hfjpBunxz7tGsZlfXfbUqfANkysQjmtXr06Hnv0kTjn3OGx5157R6vWreOMwWdFy1at4647bq/s8QBKefKfC2Pc3/4Vj7y2/n9Q/3XGJ/HsvxbFR4tWxTvzlscl970V+bWqx84t6kVERLumdeOAjk3j/Dtfi5kfLomX5nwWo+55I47s0iKa5udtyVNhGyRWoZwKC7+MwsLCyMsr+Qd0Xl5evPLKjEqaCqBiVK+ai+O6tYplq76Itz5ZFhERe7SpH0tXfhGvfbS0eLtn//VpFGVZdG5dv5ImZVuR9D2rH330UYwcOTImTZq0wW3WrFkTa9asKbEsq5pXKiSgotSpUzc6de4Sv7/ht7FD27bRqFHj+NtDD8SsV2dGy1atKns8gE3yw12axsT+XaJW9aqxYNma+Pn1L8RnK76IiIgm+XmxaHnJv2sLi7JYsvKLaFLP37dsXklfWV28eHFMnjz5G7cZO3ZsFBQUlPi54n/GbqEJ2VZdOvbyyLIsDu7VI/buslvcfuuUOOzwI6JKlaT/lwLYoGmzF8URVz4dP5n4XDz5z4Vx7YA9olHdGht/ImxmlXpl9a9//es3rn/vvfc2uo8LLrgghg4dWmJZVtW/8ti8WrZqFZMm3xorV66MFSuWR5MmTWP4uWfH9tu3rOzRADbJqrWF8cGnK+ODT1fGzA+WxNQLD4i+XVvG9Y+9GwuXrYlGdUv+3Vq1Si7q164eCz9fs4E9QsWo1Fg95phjIpfLRZZlG9wml8t94z7y8kr/yn/1lxUyHmxU7dq1o3bt2rFs6dKY9uwzcfbQ4ZU9EkCFqJKLqFHtq98WzXh/SRTUrh67bp8fr//7q/tY992xUVTJ5WLmB0sqcUq2BZX6O8vmzZvHPffcE0VFRev9mTHDm1VI07PPPB3PPv1U/PvfH8W0556Nkwf1jzY7tI2jf9ynskcDKKV2jarRsUV+dGyRHxERLRvVjo4t8qNF/ZpRq0bVGHZ4h+jcun58r0Gt2HX7/PiffrtHs4Ka8dCrcyMi4t0Fy+OJtxbE2GN3j06tCmLPHRrE6D7fj/tf+SQWLHNllc2rUq+s7rnnnvHyyy/H0Ucfvd71G7vqCpVl+fLPY+KEq2L+vHlRUFA/Djz4kDhryDlRvXr1yh4NoJTdWhbEHWd2K3484phdIiLizy9+FL++6/Vot13d+Mne20eDutVjyYovYtaHS6LvNdPinXnLi59z9q0zY3Sf78etZ/wgirIs/j5rXoy+540tfi5se3JZJdbg008/HStWrIjDDjtsvetXrFgRL730UvTs2bNc+3UbALC16Tj8wcoeAaBCzRl/RJm2q9Qrq/vvv/83rq9Tp065QxUAgK2Hz9kBACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZuSzLssoeAr6L1qxZE2PHjo0LLrgg8vLyKnscgG/Nn2ukSKzCJlq2bFkUFBTE0qVLIz8/v7LHAfjW/LlGitwGAABAssQqAADJEqsAACRLrMImysvLi5EjR3oTArDV8OcaKfIGKwAAkuXKKgAAyRKrAAAkS6wCAJAssQoAQLLEKmyi6667Ltq0aRM1a9aMrl27xosvvljZIwFskqeeeiqOPPLIaNGiReRyubjvvvsqeyQoJlZhE9x5550xdOjQGDlyZMyYMSM6deoUhx56aCxYsKCyRwMotxUrVkSnTp3iuuuuq+xRoBQfXQWboGvXrrH33nvHtddeGxERRUVF0bJlyzjrrLPi/PPPr+TpADZdLpeLe++9N4455pjKHgUiwpVVKLe1a9fGyy+/HAcddFDxsipVqsRBBx0U06ZNq8TJAGDrI1ahnD799NMoLCyM7bbbrsTy7bbbLubNm1dJUwHA1kmsAgCQLLEK5dS4ceOoWrVqzJ8/v8Ty+fPnR7NmzSppKgDYOolVKKcaNWrEnnvuGY899ljxsqKionjssceiW7dulTgZAGx9qlX2APBdNHTo0BgwYEDstddesc8++8SECRNixYoVMWjQoMoeDaDcli9fHrNnzy5+PGfOnJg5c2Y0bNgwWrVqVYmTgY+ugk127bXXxhVXXBHz5s2Lzp07x8SJE6Nr166VPRZAuT3xxBPRq1evUssHDBgQt9xyy5YfCP6DWAUAIFnuWQUAIFliFQCAZIlVAACSJVYBAEiWWAUAIFliFQCAZIlVAACSJVYBAEiWWAX4lgYOHBjHHHNM8eMDDjggzj777C0+xxNPPBG5XC6WLFmy2Y7x9XPdFFtiTmDrIVaBrdLAgQMjl8tFLpeLGjVqRPv27WPMmDHx5ZdfbvZj33PPPXHxxReXadstHW5t2rSJCRMmbJFjAVSEapU9AMDmcthhh8XNN98ca9asiYceeigGDx4c1atXjwsuuKDUtmvXro0aNWpUyHEbNmxYIfsBwJVVYCuWl5cXzZo1i9atW8cZZ5wRBx10UPz1r3+NiP/7dfall14aLVq0iA4dOkRExEcffRR9+/aN+vXrR8OGDePoo4+O999/v3ifhYWFMXTo0Khfv340atQofvWrX0WWZSWO+/XbANasWRPnnXdetGzZMvLy8qJ9+/bxhz/8Id5///3o1atXREQ0aNAgcrlcDBw4MCIiioqKYuzYsbHDDjtErVq1olOnTvHnP/+5xHEeeuih2GmnnaJWrVrRq1evEnNuisLCwjjppJOKj9mhQ4e4+uqr17vt6NGjo0mTJpGfnx+nn356rF27tnhdWWYHKCtXVoFtRq1atWLRokXFjx977LHIz8+PRx99NCIivvjiizj00EOjW7du8fTTT0e1atXikksuicMOOyxmzZoVNWrUiHHjxsUtt9wSkyZNio4dO8a4cePi3nvvjR/+8IcbPG7//v1j2rRpMXHixOjUqVPMmTMnPv3002jZsmXcfffd8ZOf/CTefvvtyM/Pj1q1akVExNixY+PWW2+NG264IXbcccd46qmn4oQTTogmTZpEz54946OPPoo+ffrE4MGD49RTT42XXnopzj333G/1+hQVFcX2228fd911VzRq1Ciee+65OPXUU6N58+bRt2/fEq9bzZo144knnoj3338/Bg0aFI0aNYpLL720TLMDlEsGsBUaMGBAdvTRR2dZlmVFRUXZo48+muXl5WXDhg0rXr/ddttla9asKX7OlClTsg4dOmRFRUXFy9asWZPVqlUre/jhh7Msy7LmzZtnl19+efH6L774Itt+++2Lj5VlWdazZ89syJAhWZZl2dtvv51FRPboo4+ud87HH388i4jss88+K162evXqrHbt2tlzzz1XYtuTTjopO+6447Isy7ILLrgg22WXXUqsP++880rt6+tat26djR8/foPrv27w4MHZT37yk+LHAwYMyBo2bJitWLGieNn111+f1a1bNyssLCzT7Os7Z4ANcWUV2Go98MADUbdu3fjiiy+iqKgojj/++Bg1alTx+t12263EfaqvvvpqzJ49O+rVq1diP6tXr4533303li5dGnPnzo2uXbsWr6tWrVrstddepW4FWGfmzJlRtWrVcl1RnD17dqxcuTIOPvjgEsvXrl0bXbp0iYiIt956q8QcERHdunUr8zE25LrrrotJkybFhx9+GKtWrYq1a9dG586dS2zTqVOnqF27donjLl++PD766KNYvnz5RmcHKA+xCmy1evXqFddff33UqFEjWrRoEdWqlfwjr06dOiUeL1++PPbcc8+47bbbSu2rSZMmmzTDul/rl8fy5csjIuLBBx+M733veyXW5eXlbdIcZXHHHXfEsGHDYty4cdGtW7eoV69eXHHFFfHCCy+UeR+VNTuw9RKrwFarTp060b59+zJvv8cee8Sdd94ZTZs2jfz8/PVu07x583jhhReiR48eERHx5Zdfxssvvxx77LHHerffbbfdoqioKJ588sk46KCDSq1fd2W3sLCweNkuu+wSeXl58eGHH27wimzHjh2L3yy2zvPPP7/xk/wGzz77bOy7777xi1/8onjZu+++W2q7V199NVatWlUc4s8//3zUrVs3WrZsGQ0bNtzo7ADl4dMAAP6///qv/4rGjRvH0UcfHU8//XTMmTMnnnjiifjlL38Z//73vyMiYsiQIfHf//3fcd9998U///nP+MUvfvGNn5Hapk2bGDBgQJx44olx3333Fe/zT3/6U0REtG7dOnK5XDzwwAOxcOHCWL58edSrVy+GDRsW55xzTkyePDnefffdmDFjRlxzzTUxefLkiIg4/fTT45133onhw4fH22+/HbfffnvccsstZTrPjz/+OGbOnFni57PPPosdd9wxXnrppXj44YfjX//6V4wYMSKmT59e6vlr166Nk046Kd5888146KGHYuTIkXHmmWdGlSpVyjQ7QLlU9k2zAJvDf77Bqjzr586dm/Xv3z9r3LhxlpeXl7Vt2zY75ZRTsqVLl2ZZ9tUbqoYMGZLl5+dn9evXz4YOHZr1799/g2+wyrIsW7VqVXbOOedkzZs3z2rUqJG1b98+mzRpUvH6MWPGZM2aNctyuVw2YMCALMu+elPYhAkTsg4dOmTVq1fPmjRpkh166KHZk08+Wfy8+++/P2vfvn2Wl5eX7b///tmkSZPK9AariCj1M2XKlGz16tXZwIEDs4KCgqx+/frZGWeckZ1//vlZp06dSr1uF110UdaoUaOsbt262SmnnJKtXr26eJuNze4NVkB55LJsA+8KAACASuY2AAAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZYhUAgGSJVQAAkiVWAQBIllgFACBZ/w+XDjKEYaby/AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Compute the F1 score\n",
        "f1 = f1_score(y_test, flat_predictions)\n",
        "\n",
        "# Print the F1 score\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DnzoDwkaXnR",
        "outputId": "6838ce30-7423-4ccb-ae30-7e56e2286b59"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9187279151943463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(flat_predictions[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdbwR73TapBZ",
        "outputId": "85de082d-8645-4bf9-d35f-4cb1299c121b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, -1, -1, 0, -1, 0, 0, -1, -1, 0, 0, -1, -1, 0, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1, 0, -1, 0, -1, 0, 0, -1, 0, -1, -1, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, -1, -1, 0, -1, 0, -1, -1, 0, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, 0, -1, 0, -1, 0, 0, -1, -1, 0, -1, 0, -1, -1, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1, 0, -1, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, -1, 0, -1, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, -1, 0, -1, 0, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, -1, -1, 0, 0, -1, -1, 0, 0, -1, 0, -1, 0, 0, 0, -1, 0, -1, -1, -1, -1, 0, -1, 0, 0, -1, 0, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0, -1, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0, -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zys6476hazA8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}